{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"Q1\"> </a>\n",
    "# Questão 1\n",
    "\n",
    "\n",
    "A inteligência artificial (IA) está presente em diversos aspectos da vida moderna, desde aplicativos até decisões empresariais. Quando falamos sobre princípios éticos em IA, um dos mais importantes é garantir que as decisões tomadas por esses sistemas sejam justas para todos. Qual princípio ético busca garantir que as decisões de IA tratem as pessoas de maneira equitativa e sem discriminação?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a.\n",
    "Eficiência\n",
    "\n",
    "\n",
    "b.\n",
    "Transparência\n",
    "\n",
    "\n",
    "c.\n",
    "Privacidade\n",
    "\n",
    "\n",
    "d.\n",
    "Justiça  [V]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"Q2\"> </a>\n",
    "# Questão 2\n",
    "\n",
    "Modelos de IA podem apresentar resultados enviesados, afetando grupos específicos de forma negativa. Imagine um sistema de IA que favorece homens na hora de recomendar candidatos para uma vaga de emprego, pois os dados históricos contêm mais homens em posições de liderança. Que tipo de problema ético está ocorrendo nesse caso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\n",
    "Insegurança de dados\n",
    "\n",
    "b.\n",
    "Invasão de privacidade\n",
    "\n",
    "c.\n",
    "Falta de transparência\n",
    "\n",
    "d.\n",
    "Preconceito e discriminação [V]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"Q3\"> </a>\n",
    "# Questão 3\n",
    "\n",
    "Muitos sistemas de IA tomam decisões com base em grandes volumes de dados históricos. Entretanto, se esses dados não forem diversificados, a IA pode perpetuar preconceitos existentes. Que fator é essencial para minimizar preconceitos em modelos de IA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\n",
    "Aumentar a complexidade dos algoritmos\n",
    "\n",
    "b.\n",
    "Garantir diversidade nos dados de treinamento [V]\n",
    "\n",
    "c.\n",
    "Usar apenas dados históricos\n",
    "\n",
    "d.\n",
    "Reduzir o número de variáveis analisadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"Q4\"> </a>\n",
    "# Questão 4\n",
    "\n",
    "A responsabilidade sobre o impacto das decisões tomadas por sistemas de IA é um tópico crucial. Quando uma IA toma uma decisão errada que prejudica uma pessoa, quem deve ser responsabilizado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\n",
    "Empresa que desenvolveu a IA  [V]\n",
    "\n",
    "b.\n",
    "Apenas o usuário do sistema\n",
    "\n",
    "c.\n",
    "Ninguém, pois a IA é independente\n",
    "\n",
    "d.\n",
    "Empresa desenvolvedora e os usuários \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"Q5\"> </a>\n",
    "# Questão 5\n",
    "\n",
    "Para garantir que a IA seja usada de maneira ética e segura, muitos governos estão criando diretrizes e regulamentações. Qual é uma das principais funções dessas regulamentações?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a.\n",
    "Proibir o uso de IA em todos os setores\n",
    "\n",
    "b.\n",
    "Garantir que a IA substitua o trabalho humano\n",
    "\n",
    "c.\n",
    "Fazer com que todas as decisões de IA sejam automatizadas\n",
    "\n",
    "d.\n",
    "Definir os limites do uso da IA em setores críticos [V]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"Q6\"> </a>\n",
    "# Questão 6\n",
    "\n",
    "O impacto social da IA é um tema amplamente debatido. Qual dos seguintes impactos pode ser considerado um risco social gerado pelo uso crescente da IA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a.\n",
    "Aumento da desigualdade de empregos em certos setores [V]\n",
    "\n",
    "b.\n",
    "Melhoria na precisão das previsões financeiras\n",
    "\n",
    "c.\n",
    "Automação de tarefas repetitivas\n",
    "\n",
    "d.\n",
    "Aumento da transparência nos processos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"Q7\"> </a>\n",
    "# Questão 7\n",
    "\n",
    "A União Europeia tem liderado a criação de regulamentações para o uso ético da IA, incluindo a implementação de leis que exigem maior transparência. Qual é o objetivo dessas regulamentações?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\n",
    "Garantir que a IA substitua decisões humanas\n",
    "\n",
    "b.\n",
    "Assegurar que as decisões da IA sejam compreensíveis e explicáveis [V]\n",
    "\n",
    "c.\n",
    "Reduzir o uso de IA no setor privado\n",
    "\n",
    "d.\n",
    "Aumentar a complexidade dos modelos de IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"Q8\"> </a>\n",
    "# Questão 8\n",
    "\n",
    "Em um cenário onde uma IA ajuda a diagnosticar doenças em pacientes, é descoberto que ela não identifica corretamente certas doenças em grupos minoritários, devido a uma falha nos dados de treinamento. Como podemos classificar essa situação?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\n",
    "Falha de segurança\n",
    "\n",
    "b.\n",
    "Invasão de privacidade\n",
    "\n",
    "c.\n",
    "Problema de eficiência\n",
    "\n",
    "d.\n",
    "Viés de dados [V]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa situação ocorre porque a IA foi treinada com um conjunto de dados que não representa adequadamente certos grupos minoritários, resultando em diagnósticos imprecisos para esses pacientes. Esse problema é conhecido como viés de dados, que acontece quando os dados utilizados para treinar um modelo não são suficientemente diversos ou contêm padrões que levam a discriminação involuntária."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"Q9\"> </a>\n",
    "# Questão 9\n",
    "\n",
    "Ao desenvolver um sistema de IA para monitorar redes sociais, uma empresa não divulga como os dados dos usuários são analisados e usados para gerar recomendações. Qual princípio ético foi violado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a.\n",
    "Transparência [V]\n",
    "\n",
    "b.\n",
    "Responsabilidade\n",
    "\n",
    "c.\n",
    "Justiça\n",
    "\n",
    "d.\n",
    "Privacidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"Q10\"> </a>\n",
    "# Questão 10\n",
    "\n",
    "Quando falamos sobre a IA e a responsabilidade dos seus criadores, por que é importante que empresas e desenvolvedores sejam responsáveis pelas tecnologias que criam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a.\n",
    "Porque as IAs são autônomas e independentes\n",
    "\n",
    "b.\n",
    "Porque a IA deve ser tratada como uma tecnologia sem impacto social\n",
    "\n",
    "c.\n",
    "Porque pode haver consequências negativas para a sociedade se o uso da IA não for regulado [V]\n",
    "\n",
    "d.\n",
    "Porque a IA nunca falha, e os erros são sempre humanos"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
